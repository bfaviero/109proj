{
 "metadata": {
  "name": "",
  "signature": "sha256:5607bca01a89fe8ec621d2c92724e11b17d9f26d0603f82f23698e2afd9a9db1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "import StringIO\n",
      "import zipfile\n",
      "import numpy as np\n",
      "import pandas as pd # pandas\n",
      "import matplotlib.pyplot as plt # module for plotting\n",
      "import datetime\n",
      "from datetime import timedelta\n",
      "from utils import *\n",
      "from datetime import timedelta\n",
      "from process_data import *\n",
      "# from pydash import flatten\n",
      "from pyq_api import get_ticker_info, get_tickers_info\n",
      "from tickers import *\n",
      "from utils import *\n",
      "from yahoo_finance import Share\n",
      "import datetime\n",
      "import matplotlib.pyplot as plt # module for plotting\n",
      "import numpy as np\n",
      "import pandas as pd # pandas\n",
      "import requests\n",
      "import StringIO\n",
      "import zipfile\n",
      "import itertools\n",
      "from __future__ import division\n",
      "import itertools\n",
      "import numpy as np\n",
      "import pandas as pd # pandas\n",
      "import datetime\n",
      "from pyq_api import get_ticker_info\n",
      "import os\n",
      "from sqlalchemy import Column, ForeignKey, String, Date, Float, Integer\n",
      "from sqlalchemy.ext.declarative import declarative_base\n",
      "from sqlalchemy.orm import relationship\n",
      "from sqlalchemy import create_engine\n",
      "from process_data import get_funds\n",
      "from utils import get_quarters\n",
      "from sqlalchemy.orm import sessionmaker\n",
      "from sqlalchemy import UniqueConstraint\n",
      "from sqlalchemy import distinct\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Here's the story of how we got all of our data!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We started with a documents containing quarterly holdings for each hedge fund:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_funds():\n",
      "    #process hedge fund holdings\n",
      "    funds = []\n",
      "    def parse_date(s):\n",
      "            #parse the particular date format of the doc\n",
      "            month, day, year = [int(i) for i in s.split('/')]\n",
      "            if year >= 0 and year <=14:\n",
      "                year += 2000\n",
      "            else:\n",
      "                year += 1900\n",
      "            date = datetime.date(year, month, day)\n",
      "            return date\n",
      "\n",
      "    for i in range(1, 9):\n",
      "        df = pd.read_csv('data/funds/fund'+str(i)+'.csv')\n",
      "        date_index = list(df.columns).index('date')\n",
      "        df['date'] = df.apply(lambda r: parse_date(r.values[date_index]), axis=1)\n",
      "        # df = df.set_index('date')\n",
      "        funds.append(df)\n",
      "    return funds\n",
      "fund = get_funds()[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Holdings example for Bluecrest Capital\"\n",
      "fund.head(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Holdings example for Bluecrest Capital\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>filer</th>\n",
        "      <th>name</th>\n",
        "      <th>ticker</th>\n",
        "      <th>date</th>\n",
        "      <th>type</th>\n",
        "      <th>current_shares</th>\n",
        "      <th>current_value</th>\n",
        "      <th>previous_shares</th>\n",
        "      <th>previous_value</th>\n",
        "      <th>current_percent</th>\n",
        "      <th>previous_percent</th>\n",
        "      <th>rank</th>\n",
        "      <th>previous_rank</th>\n",
        "      <th>change_in_shares</th>\n",
        "      <th>change_type</th>\n",
        "      <th>sector</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> BLUECREST CAPITAL MANAGEMENT LLP</td>\n",
        "      <td> SUNTECH POWER HOLDINGS CO LTD</td>\n",
        "      <td> STPFQ</td>\n",
        "      <td> 2005-12-31</td>\n",
        "      <td> SH</td>\n",
        "      <td> 20000</td>\n",
        "      <td> 545000</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 55.6844</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 999999</td>\n",
        "      <td>NaN</td>\n",
        "      <td> new</td>\n",
        "      <td> INDUSTRIALS</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "                              filer                           name ticker  \\\n",
        "0  BLUECREST CAPITAL MANAGEMENT LLP  SUNTECH POWER HOLDINGS CO LTD  STPFQ   \n",
        "\n",
        "         date type  current_shares  current_value  previous_shares  \\\n",
        "0  2005-12-31   SH           20000         545000                0   \n",
        "\n",
        "   previous_value  current_percent  previous_percent  rank  previous_rank  \\\n",
        "0               0          55.6844                 0     1         999999   \n",
        "\n",
        "   change_in_shares change_type       sector  \n",
        "0               NaN         new  INDUSTRIALS  "
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So for each hedge fund we had their name.\n",
      "For each quarter, we knew the ticker they invested in, the number of shares and percent that it made up in the portfolio, the current_value, and the sector."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Getting additional information"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Metrics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**For Consumer Price Index, GDP, and Jobless data, we downloaded and processed CSV files from the Federal Bank of Missouri.**\n",
      "    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Since the data was monthly, sometimes weekly, and sometimes daily, we had to write a small function to only pick the points closest to the ends of quarters.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_quarters():\n",
      "    #get the dates for every quarter of every year\n",
      "    data = []\n",
      "    for year in xrange(1999, 2015):\n",
      "        i = 1\n",
      "        for month, day in zip((3, 6, 9, 12), (31, 30, 30, 31)):\n",
      "            date = datetime.date(year, month, day)\n",
      "            data.append((date, i, year))\n",
      "            i+=1\n",
      "    df = pd.DataFrame(columns=['date', 'quarter', 'year'], data=data).set_index('date')\n",
      "    return df\n",
      "print \"Dates for each quarter end\"\n",
      "get_quarters().head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dates for each quarter end\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>quarter</th>\n",
        "      <th>year</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>date</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1999-03-31</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1999</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1999-06-30</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1999</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1999-09-30</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1999</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1999-12-31</th>\n",
        "      <td> 4</td>\n",
        "      <td> 1999</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2000-03-31</th>\n",
        "      <td> 1</td>\n",
        "      <td> 2000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "            quarter  year\n",
        "date                     \n",
        "1999-03-31        1  1999\n",
        "1999-06-30        2  1999\n",
        "1999-09-30        3  1999\n",
        "1999-12-31        4  1999\n",
        "2000-03-31        1  2000"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_closest_dates_to_quarters(df):\n",
      "    #Gets the dates in the dataframe closest to the ends of quarters\n",
      "    dates = []\n",
      "    quarters = get_quarters()\n",
      "    quarters = quarters.reset_index().set_index(['year', 'quarter', 'date']).index\n",
      "    for year, quarter, date in quarters:\n",
      "        row = df.loc[df.year == year]\n",
      "        if not row:\n",
      "            continue\n",
      "        row = df.loc[df.index == date]\n",
      "        if row:\n",
      "            dates.append(row.index.values[0])\n",
      "            continue\n",
      "        i = 1\n",
      "        while True:\n",
      "            #Try the five dates around this one. If that doesn't work, the data either isn't there or it's too far away from the point of interest\n",
      "            date1 = date + timedelta(days=i)\n",
      "            date2 = date - timedelta(days=i)\n",
      "            row1 = df.loc[df.index == date1]\n",
      "            row2 = df.loc[df.index == date2]\n",
      "            if row1:\n",
      "                dates.append(row1.index.values[0])\n",
      "                break\n",
      "            if row2:\n",
      "                dates.append(row2.index.values[0])\n",
      "                break\n",
      "            i+=1\n",
      "            if i>10:\n",
      "                break\n",
      "    return dates\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data(arg):\n",
      "    cpi = pd.read_csv('data/metrics/'+arg+'.csv')\n",
      "    def parse_date(s):\n",
      "        month, day, year = [int(i) for i in s.split('/')]\n",
      "        if year >= 0 and year <=14:\n",
      "            year += 2000\n",
      "        else:\n",
      "            year += 1900\n",
      "        date = datetime.date(year, month, day)\n",
      "        return date\n",
      "\n",
      "    cpi['date'] = cpi.apply(lambda r: parse_date(r.values[0]), axis=1)\n",
      "    cpi = cpi.set_index('date')\n",
      "    df = merge_with_quarters(cpi)\n",
      "    dates = get_closest_dates_to_quarters(df)\n",
      "    dates_df = pd.DataFrame(columns=['date'], data=dates).set_index('date')\n",
      "    return df.merge(dates_df, left_index=True, right_index=True).set_index(['year', 'quarter'])\n",
      "\n",
      "def get_cpi():\n",
      "    return get_data('cpi')\n",
      "\n",
      "def get_gdp():\n",
      "    return get_data('gdp')\n",
      "\n",
      "def get_jobless():\n",
      "    return get_data('jobless')\n",
      "\n",
      "def get_sentiment():\n",
      "    return get_data('sentiment')\n",
      "get_sentiment().head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>sentiment</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>year</th>\n",
        "      <th>quarter</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th rowspan=\"4\" valign=\"top\">1999</th>\n",
        "      <th>1</th>\n",
        "      <td> 104.6</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 106.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 103.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 112.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2000</th>\n",
        "      <th>1</th>\n",
        "      <td> 109.2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "              sentiment\n",
        "year quarter           \n",
        "1999 1            104.6\n",
        "     2            106.0\n",
        "     3            103.2\n",
        "     4            112.0\n",
        "2000 1            109.2"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**We also got data from the two major indices, DOW and NASDAQ**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_index(index):\n",
      "    dow = pd.read_csv('data/metrics/%s.csv' % index)\n",
      "    def transform_date(d):\n",
      "        s = str(d)\n",
      "        year, month, day = map(int, [s[:4], s[4:6], s[6:]])\n",
      "        return datetime.date(year, month, day)\n",
      "    dow.date = [transform_date(date) for date in dow.date]\n",
      "    dow = dow.set_index('date')\n",
      "    df = merge_with_quarters(dow)\n",
      "    dates = get_closest_dates_to_quarters(df)\n",
      "    dates_df = pd.DataFrame(columns=['date'], data=dates).set_index('date')\n",
      "    return df.merge(dates_df, left_index=True, right_index=True).set_index(['year', 'quarter'])[['adj_close']]\n",
      "\n",
      "def get_dow():\n",
      "    return get_index('dow')\n",
      "\n",
      "def get_snp():\n",
      "    return get_index('snp')\n",
      "get_snp().head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>adj_close</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>year</th>\n",
        "      <th>quarter</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1999</th>\n",
        "      <th>4</th>\n",
        "      <td> 1455.22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"4\" valign=\"top\">2000</th>\n",
        "      <th>1</th>\n",
        "      <td> 1498.58</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1454.60</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1436.51</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1283.27</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "              adj_close\n",
        "year quarter           \n",
        "1999 4          1455.22\n",
        "2000 1          1498.58\n",
        "     2          1454.60\n",
        "     3          1436.51\n",
        "     4          1283.27"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inflation was more trickily-formatted"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_inflation():\n",
      "    inflation = pd.read_csv('data/metrics/inflation_monthly.csv')\n",
      "    def transform_inflation(elt):\n",
      "        try:\n",
      "            return float(elt[:-1])/100.0\n",
      "        except:\n",
      "            return 999\n",
      "    for i in range(1, len(inflation.columns)):\n",
      "        col = inflation.columns[i]\n",
      "        inflation[col] = inflation.apply(lambda r: transform_inflation(r.values[i]), axis=1)\n",
      "    inflation.columns = ['YEAR', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']\n",
      "    data = []\n",
      "    for row in inflation.iterrows():\n",
      "        row = row[1]\n",
      "        year = int(row[0])\n",
      "        for i in range(1, 13):\n",
      "            inflation = row[i]\n",
      "            date = datetime.date(year, i, 1)\n",
      "            data.append([date, inflation])\n",
      "    df = pd.DataFrame(columns=['date', 'inflation'], data=data).set_index('date')\n",
      "    df = merge_with_quarters(df)\n",
      "    dates = get_closest_dates_to_quarters(df)\n",
      "    dates_df = pd.DataFrame(columns=['date'], data=dates).set_index('date')\n",
      "    return df.merge(dates_df, left_index=True, right_index=True).set_index(['year', 'quarter'])[['inflation']]\n",
      "get_inflation().head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>inflation</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>year</th>\n",
        "      <th>quarter</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th rowspan=\"4\" valign=\"top\">1999</th>\n",
        "      <th>1</th>\n",
        "      <td> 0.0228</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.0214</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.0256</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.0274</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2000</th>\n",
        "      <th>1</th>\n",
        "      <td> 0.0307</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "              inflation\n",
        "year quarter           \n",
        "1999 1           0.0228\n",
        "     2           0.0214\n",
        "     3           0.0256\n",
        "     4           0.0274\n",
        "2000 1           0.0307"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Getting ticker data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The Yahoo API"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Originally, we used the Yahoo API, by using the pyq python library to call it. It took in a ticker, two dates, and returned all of the trading data for each day."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = get_ticker_info(datetime.date(2000, 1, 1), datetime.date.today(), 'GOOG')\n",
      "data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "['GOOG', '20140327', '568.00', '568.00', '552.92', '558.46', '13100', '558.46']"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process_ticker_returns(ticker, array):\n",
      "    columns = ['ticker', 'date', 'open', 'high', 'low', 'close', 'volume', 'adj_close']\n",
      "    df = pd.DataFrame(columns=columns, data=array).drop_duplicates()\n",
      "    def transform_date(d):\n",
      "        s = str(d)\n",
      "        year, month, day = map(int, [s[:4], s[4:6], s[6:]])\n",
      "        return datetime.date(year, month, day)\n",
      "    df.date = [transform_date(date) for date in df.date]\n",
      "    df = df.set_index('date').sort().drop_duplicates()\n",
      "    unique_tickers = df.ticker.unique()\n",
      "    dfs = [df.loc[df.ticker == tick] for tick in unique_tickers]\n",
      "    for i, df in enumerate(dfs):\n",
      "        df.ticker = ticker + str(i)\n",
      "    return dfs\n",
      "print \"Google trading data\"\n",
      "process_ticker_returns('GOOG', data)[0].head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Google trading data\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>ticker</th>\n",
        "      <th>open</th>\n",
        "      <th>high</th>\n",
        "      <th>low</th>\n",
        "      <th>close</th>\n",
        "      <th>volume</th>\n",
        "      <th>adj_close</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>date</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2014-03-27</th>\n",
        "      <td> GOOG0</td>\n",
        "      <td> 568.00</td>\n",
        "      <td> 568.00</td>\n",
        "      <td> 552.92</td>\n",
        "      <td> 558.46</td>\n",
        "      <td> 13100</td>\n",
        "      <td> 558.46</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-03-28</th>\n",
        "      <td> GOOG0</td>\n",
        "      <td> 561.20</td>\n",
        "      <td> 566.43</td>\n",
        "      <td> 558.67</td>\n",
        "      <td> 559.99</td>\n",
        "      <td> 41100</td>\n",
        "      <td> 559.99</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "           ticker    open    high     low   close volume adj_close\n",
        "date                                                              \n",
        "2014-03-27  GOOG0  568.00  568.00  552.92  558.46  13100    558.46\n",
        "2014-03-28  GOOG0  561.20  566.43  558.67  559.99  41100    559.99"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**This data was not given to us quarterly. That is, the dates of the ends of quarters were not always trading days, or days a particular stock was traded on, so we also aligned this data with quarters.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def trading_data_on_date(stock, date):\n",
      "        data = get_ticker_info(date, date, stock)\n",
      "        if data:\n",
      "            return PriceData(data[0])\n",
      "        return data\n",
      "\n",
      "def _get_previous_trading_data(stock, date):\n",
      "        date = _remove_one_day(date)\n",
      "        data = trading_data_on_date(stock, date)\n",
      "        i = 0\n",
      "        while not data:\n",
      "            date = _remove_one_day(date)\n",
      "            data = trading_data_on_date(stock, date)\n",
      "            i+=1\n",
      "            if i > 5:\n",
      "                return None\n",
      "        return data\n",
      "\n",
      "def _get_next_trading_data(stock, date):\n",
      "        date = _add_one_day(date)\n",
      "        data = trading_data_on_date(stock, date)\n",
      "        i = 0\n",
      "        while not data:\n",
      "            date = _add_one_day(date)\n",
      "            data = trading_data_on_date(stock, date)\n",
      "            i+=1\n",
      "            if i > 3:\n",
      "                return None\n",
      "        return data\n",
      "\n",
      "\n",
      "\n",
      "def get_data_of_stock_on_or_around_day(stock, date, get_later_day=False):\n",
      "    data = trading_data_on_date(stock, date)\n",
      "    if data:\n",
      "        return data\n",
      "    else:\n",
      "        if get_later_day:\n",
      "            data = _get_next_trading_data(stock, date)\n",
      "        else:\n",
      "            data = _get_previous_trading_data(stock, date)\n",
      "        return data if data else None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Problems with data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Calculating return"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We initially tried calculating the return a few different ways: \n",
      "* present value - previous value for each quarter.\n",
      "* Get the value of the tickers they're holding and calculate it using their increases/decreases in value.\n",
      "\n",
      "This had a few problems:\n",
      "* PRN types are corporate debt, and we had difficulty getting those value changes. \n",
      "* We didn't know when the shares were purchased, so we couldn't accurately determined entries and exits in between quarters. It was unreasonable to assume that they held their quarterly positions for an entire quarter.  \n",
      "\n",
      "**That's when we knew we had to detect longer-term trends in their holding to seek out patterns and not rely on the estimated return.**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Old tickers\n",
      "While each of the holdings sheets contained the ticker invested in, we found that only around 3,000 of those tickers were easily gettable from the Yahoo database. The rest fell into a few different categories:\n",
      "* Ticker was simply not in this particular API's database\n",
      "* Ticker was on a different exchange that the original Quandl API we used did not account for\n",
      "* Ticker name had changed since the investment, and current APIs did not provide information for it\n",
      "* Company was acquired, merged, or the ticker was otherwise delisted"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Solving the \"lack of tickers\" problem\n",
      "To solve the problem of a lack of tickers, we actually moved to using the Quandl database, which had a nice \"quarterly\" argument to get quarterly data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_unique_tickers():\n",
      "    funds = get_funds()\n",
      "    unique_tickers = set()\n",
      "    for fund in funds:\n",
      "        for ticker in fund.ticker.values:\n",
      "            unique_tickers.add(ticker)\n",
      "    return unique_tickers\n",
      "unique_tickers = get_unique_tickers()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"%d: the total number of tickers we wanted information for \" % len(unique_tickers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7338: the total number of tickers we wanted information for \n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**First, we created a database to put the data in**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Base = declarative_base()\n",
      "\n",
      "class Ticker(Base):\n",
      "    __tablename__ = 'ticker'\n",
      "    name = Column(String(10), primary_key=True)\n",
      "    date = Column(Date, index=True, nullable=False)\n",
      "    price = Column(Float, nullable=False)\n",
      "\n",
      "engine = create_engine('sqlite:///price_db.db')\n",
      "\n",
      "# Create all tables in the engine\n",
      "#Base.metadata.create_all(engine) ## don't recreate the DB just for this report :)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def establish_session():\n",
      "    engine = create_engine('sqlite:///price_db3.db')\n",
      "    Base.metadata.bind = engine\n",
      "\n",
      "    DBSession = sessionmaker(bind=engine)\n",
      "    session = DBSession()\n",
      "    return session\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Instantiate the Quandl API call**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Quandl\n",
      "auth_token = \"v2tx16u_kQotxDgQi_22\"\n",
      "\n",
      "def get_price_history(stock, start_time, end_time, interval='quarterly'):\n",
      "    mydata = Quandl.get(\"YAHOO/\" + stock, trim_start=start_time, trim_end=end_time, collapse=interval, authtoken=auth_token)\n",
      "    return mydata\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Function to iterate through the Quandl data and put it into a database**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ticker_arrs = np.array_split(list(unique_tickers), 8)\n",
      "def process_tickers(arr):\n",
      "    auth_token = \"v2tx16u_kQotxDgQi_22\"\n",
      "\n",
      "    def get_price_history(stock, start_time, end_time, interval='quarterly'):\n",
      "        mydata = Quandl.get(\"GOOG/\" + stock, trim_start=start_time, trim_end=end_time, collapse=interval, authtoken=auth_token)\n",
      "        return mydata\n",
      "    date1 = datetime.date(1999, 3, 10)\n",
      "    date2 = datetime.date.today()\n",
      "    session = establish_session()\n",
      "    for ticker in arr:\n",
      "        try:\n",
      "            data = get_price_history(ticker, date1, date2)\n",
      "        except:\n",
      "            continue\n",
      "        print ticker\n",
      "        subdata = data[['Adjusted Close']]\n",
      "        for date, adj_close in zip(subdata.index.values, subdata.values):\n",
      "            d = pandas.Timestamp(date).date()\n",
      "            new_ticker = Ticker(name=ticker, date=d, price=adj_close[0])\n",
      "            session.add(new_ticker)\n",
      "        try:\n",
      "            session.commit()\n",
      "        except:\n",
      "            session.flush()\n",
      "    session.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**This was really slow, so we started a parallelized cluster of 8 clients in ipython notebook to speed up this computation**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython import parallel\n",
      "clients = parallel.Client()\n",
      "clients.block = False  # use asynchronous computations to make it faster\n",
      "dview = clients.direct_view()\n",
      "dview.block = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**We also had to import particular functions into that parallel cluster's context**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with dview.sync_imports():\n",
      "    import numpy\n",
      "    from sqlalchemy import create_engine\n",
      "    from sqlalchemy.ext.declarative import declarative_base\n",
      "    from sqlalchemy.orm import sessionmaker\n",
      "    from pyq_api import get_ticker_info\n",
      "    from db_dec import Ticker, quarters_df\n",
      "    from core_setup import establish_session\n",
      "    import datetime\n",
      "    import pandas\n",
      "    import Quandl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Give each client 1/500th of the data at a time for incremental progress that gets saved along the way**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lview = clients.load_balanced_view()\n",
      "for arr in np.array_split(list(unique_tickers), 500):\n",
      "    lview.apply(process_tickers, arr)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Uh Oh, more missing data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**We were now up to 4,000 tickers, but that was only 54% of all of the tickers.**  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_fund_tickers = set()\n",
      "funds = get_funds()\n",
      "for fund in funds:\n",
      "    for ticker in fund.ticker.unique():\n",
      "        all_fund_tickers.add(ticker)\n",
      "session = establish_session()\n",
      "db_tickers = set([e[0] for e in session.query(Ticker.name).distinct().all()])\n",
      "session.close()\n",
      "missing_tickers = all_fund_tickers - db_tickers\n",
      "#this length was once 4,000, I promise"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "We now had to deal with problem 2 from earlier: \n",
      "* ~~Ticker was simply not in this particular API's database~~\n",
      "* **Ticker was on a different exchange that the original Quandl API we used did not account for**\n",
      "* Ticker name had changed since the investment, and current APIs did not provide information for it\n",
      "* Company was acquired, merged, or the ticker was otherwise delisted"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Quandl queried only one exchange, the NYSE. It did not find tickers that were listed on other exchanges.**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now turned back to the Quandl Google Finance API, but this time at the metadata.  \n",
      "We could run a separate query for a ticker on a different exchange by searching for a particular tag:  \n",
      "Example tag: *\"GOOG/NASDAQ_FB\"* - \"FB\" ticker listed on the NASDAQ"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We needed to find every possible tag, so we iterated through every tag in Quandl's database and saved them to a txt file.  \n",
      "This involved 272 API calls to get 72,000 tags."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_tags_to_file():\n",
      "    def get_url(page):\n",
      "        url = \"http://www.quandl.com/api/v2/datasets.csv?query=*&source_code=GOOG&per_page=300&page=\" + str(page)+'&auth_token=SE-S5ZTaR6AQKVvapR6x'\n",
      "        return url\n",
      "    def get_metadata():\n",
      "        for page in xrange(1, 273):\n",
      "            url = get_url(page)\n",
      "            data = pd.read_csv(url, header=0)\n",
      "            data.columns = ['tag', 'name', 'date1', 'date2', 'interval', 'date']\n",
      "            yield data\n",
      "    with open('tags.txt', 'w') as output: \n",
      "        for data in get_metadata():\n",
      "            tags = data.tag.values\n",
      "            output.write('\\n'.join(tags))\n",
      "def get_tags():\n",
      "    with open('tags.txt') as f:\n",
      "        tags = [line.rstrip() for line in f]\n",
      "        return tags\n",
      "tags = get_tags()\n",
      "ticker_tag = {tag.split('_')[-1]: tag for tag in tags}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.array(tags), len(tags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "(array(['GOOG/NASDAQ_FB', 'GOOG/NASDAQ_TSLA', 'GOOG/NASDAQ_MSFT', ...,\n",
        "        'GOOG/ASX_CND', 'GOOG/IST_IHGZT', 'GOOG/FRA_SUU'], \n",
        "       dtype='|S37'), 71908)"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**We also parse this to extract the exchange and ticker**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_exchange_and_ticker(tag):\n",
      "    #parse a tag to get the exchange and ticker\n",
      "    index = tag.find('_')\n",
      "    if index == -1:\n",
      "        return None, None\n",
      "    exchange, ticker = tag[5:index], tag[index+1:]\n",
      "    return exchange, ticker\n",
      "def is_major_exchange(exchange):\n",
      "    #check if a tag is associated with NYSE or NASDAQ\n",
      "    return exchange == 'NYSE' or exchange == 'NASDAQ'\n",
      "tag = tags[0]\n",
      "exchange, ticker = get_exchange_and_ticker(tags[0])\n",
      "print \"Tag: \\t\\t%s\\nExchange: \\t%s\\nTicker: \\t%s\" % (tag, exchange, ticker)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tag: \t\tGOOG/NASDAQ_FB\n",
        "Exchange: \tNASDAQ\n",
        "Ticker: \tFB\n"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**We then iterated through every ticker to find every possible tag for it. Tickers listed on multiple exchanges had multiple tags**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ticker_tag_map = {} #map tickers to possible tags\n",
      "skipped = set() #skip tags like \"DJI\", which are indices like the Dow since we only want tickers\n",
      "not_found = missing_tickers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#iterate through all missing tickers\n",
      "for ticker in not_found:\n",
      "    #look through every tag\n",
      "    for tag in tags:\n",
      "        \n",
      "        #try to parse the exchange and ticker\n",
      "        exchange, alleged_ticker = get_exchange_and_ticker(tag) \n",
      "        \n",
      "        #if the parsing messed up, it's probably a bad tag.\n",
      "        if not (exchange and alleged_ticker): \n",
      "            break\n",
      "        alleged_ticker = alleged_ticker.replace('_', '')\n",
      "        \n",
      "        #if our ticker matches the tag's ticker, set that tag as the main one\n",
      "        if alleged_ticker == ticker:\n",
      "            ticker_tag_map[ticker] = tag\n",
      "            #if at any point we see a NASDAQ or NYSE, set that as the tag and stop looking\n",
      "            if is_major_exchange(exchange):\n",
      "                break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tickers we're still missing\n",
      "still_missing = not_found - set(ticker_tag_map.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**We were now up to 5100 tickers**  \n",
      "With 71% of tickers, we felt a little more comfortable proceeding.  \n",
      "What happened with the rest of the tickers? That comes down to problems 3 and 4.\n",
      "* ~~Ticker was simply not in this particular API's database~~\n",
      "* ~~Ticker was on a different exchange that the original Quandl API we used did not account for~~\n",
      "* **Ticker name had changed since the investment, and current APIs did not provide information for it**\n",
      "* **Company was acquired, merged, or the ticker was otherwise delisted**  \n",
      "\n",
      "This was data that is not easy to retrieve. I started a manual process to iterate through each one, and copy the name to my clipboard so I could do a quick Google search for it. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from AppKit import NSPasteboard, NSArray\n",
      "def write_to_clipboard(text=\"hello world\"):\n",
      "    pb = NSPasteboard.generalPasteboard()\n",
      "    pb.clearContents()\n",
      "    a = NSArray.arrayWithObject_(text)\n",
      "    pb.writeObjects_(a)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**First, though, I generated ALL possible tags for the \"still-missing\" tickers to see if maybe the ticker was contained in the tag but malformatted using the more permissive \"ticker in tag\" instead of \"ticker == alleged_ticker\" from the parsed tag**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tickers that are still missing\n",
      "still_missing = not_found - set(ticker_tag_map.keys())\n",
      "\n",
      "#tag-to-ticker mapping\n",
      "remaining_ticker_tag_map = {}\n",
      "for ticker in still_missing:\n",
      "    remaining_ticker_tag_map[ticker] = []\n",
      "    for tag in tags:\n",
      "        exchange, alleged_ticker = get_exchange_and_ticker(tag)\n",
      "        if not (exchange and alleged_ticker):\n",
      "            skipped.add(tag)\n",
      "            break\n",
      "        alleged_ticker = alleged_ticker.replace('_', '')\n",
      "        if ticker in alleged_ticker:\n",
      "            remaining_ticker_tag_map[ticker].append(tag)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"%d tickers still missing \" % len(still_missing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2189 tickers still missing \n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "remaining_seen = set()\n",
      "remaining_good_ones = {}\n",
      "#Wrap the text in a URL to easily paste into the browser for a google search\n",
      "def google(text):\n",
      "    return 'http://www.google.com/search?q=%s' % text\n",
      "\n",
      "#iterate through still-missing tags\n",
      "for key in remaining_ticker_tag_map.keys():\n",
      "    #this process may get interrupted, so keep track of tickers we've seen\n",
      "    if key in remaining_seen:\n",
      "        continue\n",
      "        \n",
      "    #get all possible tags\n",
      "    options = remaining_ticker_tag_map[key] \n",
      "    \n",
      "    #if there are no possible tags, quic\n",
      "    if not options:\n",
      "        continue\n",
      "\n",
      "    #get the ticker's name and sector that we already know\n",
      "    sector, name = ticker_sector_map[key]\n",
      "    print key, options, sector, name\n",
      "    \n",
      "    #write the ticker name to the clipboard\n",
      "    write_to_clipboard(name + ' ticker')\n",
      "    \n",
      "    \"\"\"\n",
      "    this is the manual input part....\n",
      "    For each ticker, I googled it to see if I could find meaningful results. In the 60 tickers I went through, \n",
      "    \"\"\"\n",
      "    choice = raw_input(\"Which one?\")\n",
      "    break\n",
      "    remaining_seen.add(key)\n",
      "    if choice == '':\n",
      "        continue\n",
      "    elif choice[0]=='0':\n",
      "        mergers[key] = choice[1:]\n",
      "        continue\n",
      "    elif choice[0] == '1':\n",
      "        acquired[key] = choice[1:]\n",
      "    else:\n",
      "        print choice\n",
      "        old_ticker_new_ticker_map[key] = choice\n",
      "    \n",
      "    continue\n",
      "    raise Exception\n",
      "    choice = int(choice)\n",
      "    if choice == 0:\n",
      "        continue\n",
      "    chosen = options[choice-1]\n",
      "    remaining_good_ones[key] = chosen"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PAS ['GOOG/NASDAQ_IPAS', 'GOOG/PINK_SPASF', 'GOOG/PINK_PASO', 'GOOG/OTC_PASO'] CONSUMER STAPLES PepsiAmericas Inc. (New)\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Which one?0\n"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "remaining_seen = set(['SPK', 'CDO', 'LIFC', 'LCCI', 'WLS', 'CTX', 'LU', 'FLBC', 'LPAC', 'SIB', 'NMGA', 'SEMA', 'NYM', 'EMUS', 'DPL', 'BEV', 'GRS', 'TKF', 'AGT', 'LC', 'SEMI', 'PRM', 'NLX', 'NLC', 'IUSA', 'LI', 'IIG', 'SAX', 'LSS', 'VLP', 'LZ', 'TAA', 'GW', 'TSE', 'GR', 'GP', 'JAV', 'SHY', 'ZF', 'JAS', 'HAND', 'MRL', 'JNK', 'ZX', 'DIVX', 'HGCF', 'GRL', 'TSA', 'GI', 'PREM', 'CFL', 'KBL', 'SNN', 'PNP', 'DBC', 'MRB', 'CFB', 'SNP', 'APB', 'EDN', 'SFA'])\n",
      "old_ticker_new_ticker_map = {'GRS': 'GOOG/NYSE_AUQ', 'SHY': 'GOOG/NYSEARCA_SHY', 'ZF': 'GOOG/NYSE_ZF', 'WLS': 'GOOG/NYSE_WLH', 'JNK': 'GOOG/NYSEARCA_JNK', 'ZX': 'GOOG/NYSE_ZX', 'HGCF': 'GOOG/NASDAQ_YDKN', 'TKF': 'GOOG/NYSE_TKF', 'SEMI': 'GOOG/NYSE_WFR', 'DBC': 'GOOG/AMEX_DBC', 'EDN': 'GOOG/NYSE_EDN', 'IIG': 'GOOG/AMEX_EXE', 'SNP': 'GOOG/NYSE_SNP', 'APB': 'GOOG/NYSE_APB', 'VLP': 'GOOG/NYSE_VLO'}\n",
      "print \"Manually analyzed \"+str(len(remaining_seen))+\" tickers\"\n",
      "print str(len(old_ticker_new_ticker_map)) + \" were now listed under a new ticker name. These, I proceeded to search through the Quandl Tag database for  to find their new tag.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Manually analyzed 61 tickers\n",
        "15 were now listed under a new ticker name. These, I proceeded to search through the Quandl Tag database for  to find their new tag.\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since this process was slow and laborious, we decided it would be more productive to go ahead and start the analysis! with most of the tickers under our belt."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}